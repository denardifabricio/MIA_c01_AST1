{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from src.util import *\n",
    "from src.arima import ARIMAModel\n",
    "from src.sarima import SARIMAModel\n",
    "from src.dense import DenseClassifier, DenseNN\n",
    "from src.lstm import LSTM\n",
    "from src.cnn import CNN1D, CNNLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = os.getcwd()\n",
    "MODELS = os.path.join(ROOT, 'models')\n",
    "METRICS = os.path.join(ROOT, 'metrics')\n",
    "DATA = os.path.join(ROOT, 'dataset')\n",
    "FIGURES = os.path.join(ROOT, 'figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar si hay GPU disponible y configurar el dispositivo\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construir Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file from the dataset folder\n",
    "file_path = os.path.join(DATA, 'TrafficTwoMonth.csv')\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Create datetime column\n",
    "df = create_datetime_column(df)\n",
    "df.drop(['Time', 'Date', 'Day of the week'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación del Estado del Tráfico\n",
    "\n",
    "En esta sección abordaremos un problema de clasificación multiclase para predecir el estado del tráfico. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clases a Predecir\n",
    "El estado del tráfico se clasifica en 4 categorías:\n",
    "- **Low**: Tráfico bajo\n",
    "- **Normal**: Tráfico normal \n",
    "- **High**: Tráfico alto\n",
    "- **Heavy**: Tráfico muy alto/congestionado\n",
    "\n",
    "## Datos de Entrada\n",
    "Como variables de entrada se utilizan conteos de diferentes tipos de vehículos, medidos cada 15 minutos:\n",
    "- Cantidad de automóviles\n",
    "- Cantidad de motocicletas \n",
    "- Cantidad de colectivos/buses\n",
    "- Cantidad de camiones\n",
    "\n",
    "## Modelo y División de Datos\n",
    "Para resolver este problema de clasificación se implementará una red neuronal. Los datos se dividirán de la siguiente manera:\n",
    "- 70% para entrenamiento (train)\n",
    "- 15% para validación (validation)\n",
    "- 15% para prueba (test)\n",
    "\n",
    "Esta división nos permitirá entrenar el modelo, ajustar hiperparámetros y evaluar su rendimiento de manera adecuada en datos no vistos durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar los datos de entrada (X)\n",
    "input_columns = ['CarCount', 'BikeCount', 'BusCount', 'TruckCount']\n",
    "X = df[input_columns].values\n",
    "\n",
    "# Escalar los datos de entrada usando DataScaler por columna\n",
    "scalers = []\n",
    "X_scaled_list = []\n",
    "\n",
    "for col in range(X.shape[1]):\n",
    "    scaler = DataScaler(feature_range=(0, 1))\n",
    "    X_scaled_col = scaler.fit_transform(X[:, col])\n",
    "    scalers.append(scaler)\n",
    "    X_scaled_list.append(X_scaled_col)\n",
    "\n",
    "# Combinar las columnas escaladas\n",
    "X_scaled = np.column_stack(X_scaled_list)\n",
    "\n",
    "# Preparar las etiquetas (y)\n",
    "class_mapping = {'low': 0, 'normal': 1, 'high': 2, 'heavy': 3}\n",
    "y = df['Traffic Situation'].map(class_mapping).values\n",
    "\n",
    "# Convertir a tensores de PyTorch\n",
    "X_tensor = torch.FloatTensor(X_scaled)\n",
    "y_tensor = torch.LongTensor(y)\n",
    "\n",
    "# Mezclar los datos antes de dividir\n",
    "indices = torch.randperm(len(X_tensor))\n",
    "X_tensor = X_tensor[indices]\n",
    "y_tensor = y_tensor[indices]\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento, validación y test\n",
    "total_samples = len(X_tensor)\n",
    "train_size = int(0.7 * total_samples)\n",
    "val_size = int(0.15 * total_samples)\n",
    "test_size = total_samples - train_size - val_size\n",
    "\n",
    "X_train = X_tensor[:train_size]\n",
    "y_train = y_tensor[:train_size]\n",
    "\n",
    "X_val = X_tensor[train_size:train_size+val_size]\n",
    "y_val = y_tensor[train_size:train_size+val_size]\n",
    "\n",
    "X_test = X_tensor[train_size+val_size:]\n",
    "y_test = y_tensor[train_size+val_size:]\n",
    "\n",
    "# Crear DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(list(zip(X_train, y_train)), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(list(zip(X_val, y_val)), batch_size=batch_size)\n",
    "test_loader = DataLoader(list(zip(X_test, y_test)), batch_size=batch_size)\n",
    "\n",
    "# Calcular los pesos de las clases para manejar el desbalance\n",
    "class_counts = torch.bincount(y_tensor)\n",
    "num_classes = len(class_counts)\n",
    "class_weights = class_counts.sum() / (num_classes * class_counts.float())\n",
    "class_weights = class_weights.to(device)\n",
    "\n",
    "print(\"\\nPesos por clase:\")\n",
    "for i, weight in enumerate(class_weights):\n",
    "    print(f\"Clase {i}: {weight:.4f}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"Dimensiones de los datos:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(\"--------------------------------\")\n",
    "print(f\"Distribución de clases en el conjunto de entrenamiento:\")\n",
    "print(pd.Series(y_train.numpy()).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER = {'params': \"classifier.pth\",\n",
    "              'metrics': \"classifier_metrics.json\",\n",
    "              'plot_metrics': \"classifier_metrics.png\",\n",
    "              'confusion_matrix': \"classifier_confusion_matrix.png\"}\n",
    "\n",
    "# Crear el modelo\n",
    "input_size = len(input_columns)  # 4 features\n",
    "hidden_sizes = [32, 32]  # Dos capas ocultas\n",
    "output_size = 4  # 4 clases\n",
    "classifier = DenseClassifier(input_size=input_size, \n",
    "                             hidden_sizes=hidden_sizes, \n",
    "                             num_classes=output_size, \n",
    "                             device=device,\n",
    "                             class_weights=class_weights,\n",
    "                             init_method='xavier_normal')\n",
    "\n",
    "# Cargar métricas si existen, sino definirlas\n",
    "metrics_path = os.path.join(METRICS, CLASSIFIER['metrics'])\n",
    "if os.path.exists(metrics_path):\n",
    "    with open(metrics_path, 'r') as f:\n",
    "        traffic_classifier_metrics = json.load(f)\n",
    "else:\n",
    "    traffic_classifier_metrics = {'epochs': [], \n",
    "                                  'loss': {'train': [], 'val': []}, \n",
    "                                  'accuracy': {'train': [], 'val': []}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir optimizador\n",
    "optimizer = torch.optim.RMSprop(classifier.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "# Cargar modelo si existe\n",
    "model_path = os.path.join(MODELS, CLASSIFIER['params'])\n",
    "if os.path.exists(model_path):\n",
    "    classifier.load_state_dict(torch.load(model_path))\n",
    "# Entrenar modelo\n",
    "traffic_classifier_metrics = classifier.fit(train_loader=train_loader, \n",
    "                                            val_loader=val_loader, \n",
    "                                            optimizer=optimizer, \n",
    "                                            num_epochs=50, \n",
    "                                            print_every=10,\n",
    "                                            metrics=traffic_classifier_metrics)\n",
    "# Guardar métricas\n",
    "with open(os.path.join(METRICS, CLASSIFIER['metrics']), 'w') as f:\n",
    "    json.dump(traffic_classifier_metrics, f)\n",
    "# Guardar modelo\n",
    "torch.save(classifier.state_dict(), os.path.join(MODELS, CLASSIFIER['params']))\n",
    "# Graficar pérdidas\n",
    "plot_metrics(history=traffic_classifier_metrics, \n",
    "            title='Métricas - Traffic Classifier', \n",
    "            save_path=os.path.join(FIGURES, CLASSIFIER['plot_metrics']))\n",
    "# Matriz de confusión\n",
    "cm, metrics = classifier.compute_confusion_matrix(test_loader, \n",
    "                                                 plot=True, \n",
    "                                                 save_path=os.path.join(FIGURES, CLASSIFIER['confusion_matrix']))\n",
    "# Imprimir métricas\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
